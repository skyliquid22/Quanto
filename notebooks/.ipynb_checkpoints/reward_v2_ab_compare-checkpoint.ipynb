{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reward v1 vs Reward v2 Comparison\n",
        "\n",
        "Use this notebook to compare two experiments across execution, regime, and stability layers. Edit only the parameters in the next cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Parameters (edit experiment IDs and optional labels)\n",
        "# ---------------------------------------------------------------------------\n",
        "CANDIDATE_EXPERIMENT_ID = \"CANDIDATE_EXPERIMENT_ID_HERE\"\n",
        "BASELINE_EXPERIMENT_ID = \"BASELINE_EXPERIMENT_ID_HERE\"\n",
        "\n",
        "CANDIDATE_LABEL = \"Candidate (reward_v2)\"\n",
        "BASELINE_LABEL = \"Baseline (reward_v1)\"\n",
        "\n",
        "EXPORT_DIR = Path(\"notebooks/_out\")\n",
        "STRICT = False\n",
        "\n",
        "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from typing import Any, Iterable, Sequence\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
        "\n",
        "\n",
        "def _resolve_project_root(start: Path | None = None) -> Path:\n",
        "    start = start or Path().resolve()\n",
        "    for candidate in [start, *start.parents]:\n",
        "        if (candidate / \"research\").exists() and (candidate / \"scripts\").exists():\n",
        "            return candidate\n",
        "    return start\n",
        "\n",
        "\n",
        "PROJECT_ROOT = _resolve_project_root()\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "try:\n",
        "    from research.experiments.registry import ExperimentRegistry\n",
        "except Exception as exc:  # pragma: no cover - notebook fallback\n",
        "    warnings.warn(f\"Could not import ExperimentRegistry: {exc}\")\n",
        "    ExperimentRegistry = None\n",
        "\n",
        "REGISTRY = ExperimentRegistry() if ExperimentRegistry else None\n",
        "KNOWN_ARTIFACT_HINTS = [\n",
        "    \"evaluation/metrics.json\",\n",
        "    \"evaluation/regime_slices.json\",\n",
        "    \"evaluation/timeseries.json\",\n",
        "    \"promotion/qualification_report.json\",\n",
        "    \"runs/rollout.json\",\n",
        "]\n",
        "\n",
        "\n",
        "def _has_known_artifacts(path: Path) -> bool:\n",
        "    return any((path / rel).exists() for rel in KNOWN_ARTIFACT_HINTS)\n",
        "\n",
        "\n",
        "def resolve_experiment_dir(experiment_id: str) -> Path:\n",
        "    token = (experiment_id or \"\").strip()\n",
        "    if not token:\n",
        "        raise ValueError(\"experiment_id must be provided\")\n",
        "    if REGISTRY:\n",
        "        try:\n",
        "            record = REGISTRY.resolve_identifier(token)\n",
        "            print(f\"Resolved {token} via registry \u2192 {record.root}\")\n",
        "            return record.root\n",
        "        except FileNotFoundError:\n",
        "            pass\n",
        "    search_roots = [\n",
        "        PROJECT_ROOT / \".quanto_data\" / \"experiments\",\n",
        "        PROJECT_ROOT / \".quanto\" / \"experiments\",\n",
        "        PROJECT_ROOT / \"experiments\",\n",
        "        PROJECT_ROOT / \"orchestration\" / \"out\",\n",
        "    ]\n",
        "    for root in search_roots:\n",
        "        candidate = root / token\n",
        "        if candidate.exists() and _has_known_artifacts(candidate):\n",
        "            print(f\"Resolved {token} via filesystem scan \u2192 {candidate}\")\n",
        "            return candidate\n",
        "    message = f\"Artifacts for {token} were not found in registry or search roots.\"\n",
        "    if STRICT:\n",
        "        raise FileNotFoundError(message)\n",
        "    warnings.warn(message)\n",
        "    return PROJECT_ROOT / token\n",
        "\n",
        "\n",
        "candidate_dir = resolve_experiment_dir(CANDIDATE_EXPERIMENT_ID)\n",
        "baseline_dir = resolve_experiment_dir(BASELINE_EXPERIMENT_ID)\n",
        "print(f\"Candidate directory: {candidate_dir}\")\n",
        "print(f\"Baseline directory:  {baseline_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "ARTIFACT_CANDIDATES: dict[str, list[str]] = {\n",
        "    \"metrics\": [\"evaluation/metrics.json\", \"eval/metrics.json\"],\n",
        "    \"regime_slices\": [\"evaluation/regime_slices.json\", \"eval/regime_slices.json\"],\n",
        "    \"timeseries\": [\"evaluation/timeseries.json\", \"evaluation/time_series.json\"],\n",
        "    \"rollout\": [\"runs/rollout.json\", \"evaluation/rollout.json\"],\n",
        "    \"qualification\": [\n",
        "        \"promotion/qualification_report.json\",\n",
        "        \"qualification/report.json\",\n",
        "    ],\n",
        "    \"execution_metrics\": [\"evaluation/execution_metrics.json\", \"execution/metrics.json\"],\n",
        "}\n",
        "\n",
        "\n",
        "def load_json(path: Path) -> dict[str, Any] | None:\n",
        "    if not path.exists():\n",
        "        return None\n",
        "    try:\n",
        "        return json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "    except json.JSONDecodeError as exc:\n",
        "        warnings.warn(f\"Failed to parse {path}: {exc}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def read_artifact(exp_dir: Path, rel_paths: Sequence[str]) -> dict[str, Any] | None:\n",
        "    for rel in rel_paths:\n",
        "        candidate = exp_dir / rel\n",
        "        payload = load_json(candidate)\n",
        "        if payload is not None:\n",
        "            return payload\n",
        "    return None\n",
        "\n",
        "\n",
        "def collect_artifacts(exp_dir: Path) -> dict[str, dict[str, Any] | None]:\n",
        "    return {name: read_artifact(exp_dir, rels) for name, rels in ARTIFACT_CANDIDATES.items()}\n",
        "\n",
        "\n",
        "candidate_artifacts = collect_artifacts(candidate_dir)\n",
        "baseline_artifacts = collect_artifacts(baseline_dir)\n",
        "print(\"Loaded artifacts:\")\n",
        "print(\"  Candidate \u2192\", {k: v is not None for k, v in candidate_artifacts.items()})\n",
        "print(\"  Baseline  \u2192\", {k: v is not None for k, v in baseline_artifacts.items()})\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from collections.abc import Mapping\n",
        "\n",
        "\n",
        "def dig(payload: Mapping | None, path: Sequence[str]) -> Any:\n",
        "    current: Any = payload\n",
        "    for key in path:\n",
        "        if not isinstance(current, Mapping):\n",
        "            return None\n",
        "        current = current.get(key)\n",
        "    return current\n",
        "\n",
        "\n",
        "def get_first(mapping: Mapping | None, keys: Sequence[str], default: Any = None) -> Any:\n",
        "    if not isinstance(mapping, Mapping):\n",
        "        return default\n",
        "    for key in keys:\n",
        "        if key in mapping:\n",
        "            return mapping[key]\n",
        "    return default\n",
        "\n",
        "\n",
        "def extract_execution_summary(\n",
        "    artifacts: dict[str, Any],\n",
        "    *,\n",
        "    role_key: str = \"candidate\",\n",
        "    peer_qualification: Mapping | None = None,\n",
        "    peer_role_key: str | None = None,\n",
        ") -> dict[str, Any]:\n",
        "    summary_paths = [\n",
        "        [\"qualification\", \"execution_qualification\", role_key, \"summary\"],\n",
        "        [\"execution_metrics\", \"summary\"],\n",
        "        [\"execution_metrics\"],\n",
        "    ]\n",
        "    summary: Mapping | None = None\n",
        "    for path in summary_paths:\n",
        "        summary = dig(artifacts, path)\n",
        "        if isinstance(summary, Mapping):\n",
        "            break\n",
        "    if summary is None and peer_qualification is not None and peer_role_key:\n",
        "        summary = dig(peer_qualification, [\"execution_qualification\", peer_role_key, \"summary\"])\n",
        "    if not isinstance(summary, Mapping):\n",
        "        return {}\n",
        "    keys = [\n",
        "        \"fill_rate\",\n",
        "        \"reject_rate\",\n",
        "        \"partial_fill_rate\",\n",
        "        \"avg_slippage_bps\",\n",
        "        \"p95_slippage_bps\",\n",
        "        \"total_fees\",\n",
        "        \"turnover_realized\",\n",
        "        \"execution_halts\",\n",
        "    ]\n",
        "    result = {k: summary.get(k) for k in keys}\n",
        "    result[\"source\"] = summary_paths[0][1] if summary_paths else \"unknown\"\n",
        "    return result\n",
        "\n",
        "\n",
        "def extract_regime_frame(artifacts: dict[str, Any]) -> pd.DataFrame:\n",
        "    slices = dig(artifacts, [\"regime_slices\", \"performance_by_regime\"]) or {}\n",
        "    if not isinstance(slices, Mapping):\n",
        "        return pd.DataFrame()\n",
        "    frame = pd.DataFrame(slices).T\n",
        "    return frame.sort_index()\n",
        "\n",
        "\n",
        "def build_step_frame(artifacts: dict[str, Any]) -> pd.DataFrame:\n",
        "    series_candidates = []\n",
        "    rollout = artifacts.get(\"rollout\")\n",
        "    if isinstance(rollout, Mapping):\n",
        "        series_candidates.append(rollout.get(\"series\"))\n",
        "    series_candidates.append(artifacts.get(\"timeseries\"))\n",
        "    series: Mapping | None = None\n",
        "    for candidate in series_candidates:\n",
        "        if isinstance(candidate, Mapping) and candidate:\n",
        "            series = candidate\n",
        "            break\n",
        "    if not isinstance(series, Mapping):\n",
        "        return pd.DataFrame()\n",
        "    max_len = max((len(v) for v in series.values() if isinstance(v, Sequence)), default=0)\n",
        "    df = pd.DataFrame(index=range(max_len))\n",
        "\n",
        "    def assign(name: str, values: Sequence | None) -> None:\n",
        "        if values is None:\n",
        "            return\n",
        "        df[name] = pd.Series(values)\n",
        "\n",
        "    assign(\"timestamp\", pd.to_datetime(series.get(\"timestamps\")))\n",
        "    assign(\"account_value\", series.get(\"account_value\"))\n",
        "    assign(\"returns\", series.get(\"returns\"))\n",
        "    assign(\"transaction_costs\", series.get(\"transaction_costs\"))\n",
        "    assign(\"exposure\", series.get(\"exposures\"))\n",
        "\n",
        "    weights = series.get(\"weights\")\n",
        "    if isinstance(weights, Mapping) and weights:\n",
        "        symbols = sorted(weights)\n",
        "        matrix = np.column_stack([weights[sym] for sym in symbols])\n",
        "        turnover = 0.5 * np.abs(np.diff(matrix, axis=0)).sum(axis=1)\n",
        "        turnover = np.concatenate([[0.0], turnover])\n",
        "        df[\"turnover\"] = pd.Series(turnover)\n",
        "        df[\"max_weight\"] = pd.Series(matrix.max(axis=1))\n",
        "        top_n = np.sort(matrix, axis=1)[:, -min(5, matrix.shape[1]):]\n",
        "        df[\"top5_weight\"] = pd.Series(top_n.sum(axis=1))\n",
        "\n",
        "    if \"account_value\" in df:\n",
        "        rolling_max = df[\"account_value\"].cummax().replace(0, np.nan)\n",
        "        df[\"drawdown\"] = 1.0 - (df[\"account_value\"] / rolling_max)\n",
        "\n",
        "    regime = series.get(\"regime\")\n",
        "    if isinstance(regime, Mapping) and isinstance(regime.get(\"values\"), Sequence):\n",
        "        values = np.array(regime[\"values\"], dtype=float)\n",
        "        feature_names = regime.get(\"feature_names\") or [f\"regime_{i}\" for i in range(values.shape[1])]\n",
        "        for idx, feature in enumerate(feature_names):\n",
        "            if idx < values.shape[1]:\n",
        "                df[f\"regime_{feature}\"] = pd.Series(values[:, idx])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def summarize_stability(df: pd.DataFrame) -> dict[str, Any]:\n",
        "    summary: dict[str, Any] = {\"steps\": int(len(df))}\n",
        "    if \"turnover\" in df:\n",
        "        summary[\"avg_turnover\"] = float(df[\"turnover\"].mean())\n",
        "        summary[\"p95_turnover\"] = float(df[\"turnover\"].quantile(0.95))\n",
        "        summary[\"max_turnover\"] = float(df[\"turnover\"].max())\n",
        "    if \"drawdown\" in df:\n",
        "        summary[\"max_drawdown\"] = float(df[\"drawdown\"].max())\n",
        "        summary[\"avg_drawdown\"] = float(df[\"drawdown\"].mean())\n",
        "    if \"account_value\" in df and df[\"account_value\"].notna().any():\n",
        "        start = df[\"account_value\"].dropna().iloc[0]\n",
        "        end = df[\"account_value\"].dropna().iloc[-1]\n",
        "        summary[\"total_return\"] = float(end / start - 1.0) if start else None\n",
        "    if \"returns\" in df and df[\"returns\"].notna().any():\n",
        "        ann_factor = 252 ** 0.5\n",
        "        summary[\"volatility_ann\"] = float(df[\"returns\"].std() * ann_factor)\n",
        "        mean = df[\"returns\"].mean()\n",
        "        std = df[\"returns\"].std()\n",
        "        summary[\"sharpe\"] = float(mean / std * np.sqrt(252)) if std else None\n",
        "    if \"max_weight\" in df:\n",
        "        summary[\"avg_max_weight\"] = float(df[\"max_weight\"].mean())\n",
        "    if \"top5_weight\" in df:\n",
        "        summary[\"avg_top5_weight\"] = float(df[\"top5_weight\"].mean())\n",
        "    if \"exposure\" in df:\n",
        "        summary[\"avg_exposure\"] = float(df[\"exposure\"].mean())\n",
        "    return summary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "shared_qualification = candidate_artifacts.get(\"qualification\") or {}\n",
        "layer1_rows: list[dict[str, Any]] = []\n",
        "for label, artifacts, role_key, peer_role in [\n",
        "    (BASELINE_LABEL, baseline_artifacts, \"candidate\", \"baseline\"),\n",
        "    (CANDIDATE_LABEL, candidate_artifacts, \"candidate\", None),\n",
        "]:\n",
        "    summary = extract_execution_summary(\n",
        "        artifacts,\n",
        "        role_key=role_key,\n",
        "        peer_qualification=shared_qualification,\n",
        "        peer_role_key=peer_role,\n",
        "    )\n",
        "    summary[\"label\"] = label\n",
        "    layer1_rows.append(summary)\n",
        "\n",
        "layer1_df = pd.DataFrame(layer1_rows).set_index(\"label\") if layer1_rows else pd.DataFrame()\n",
        "display(layer1_df)\n",
        "\n",
        "if all(idx in layer1_df.index for idx in [BASELINE_LABEL, CANDIDATE_LABEL]):\n",
        "    numeric_cols = layer1_df.select_dtypes(include=[np.number]).columns\n",
        "    layer1_delta = layer1_df.loc[CANDIDATE_LABEL, numeric_cols] - layer1_df.loc[BASELINE_LABEL, numeric_cols]\n",
        "else:\n",
        "    layer1_delta = pd.Series(dtype=float)\n",
        "\n",
        "if not layer1_delta.empty:\n",
        "    commentary = [\n",
        "        f\"Turnover delta: {layer1_delta.get('turnover_realized', float('nan')):+.3f}\",\n",
        "        f\"Fill-rate delta: {layer1_delta.get('fill_rate', float('nan')):+.3f}\",\n",
        "        f\"Total fees delta: {layer1_delta.get('total_fees', float('nan')):+.3f}\",\n",
        "    ]\n",
        "else:\n",
        "    commentary = [\"Execution metrics unavailable for comparison.\"]\n",
        "\n",
        "display(Markdown(\"\n",
        "\".join(f\"* {line}\" for line in commentary)))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "baseline_regime = extract_regime_frame(baseline_artifacts)\n",
        "candidate_regime = extract_regime_frame(candidate_artifacts)\n",
        "\n",
        "if baseline_regime.empty and candidate_regime.empty:\n",
        "    print(\"No regime slice data available.\")\n",
        "    regime_comparison = pd.DataFrame()\n",
        "    regime_delta = pd.DataFrame()\n",
        "    regime_sharpe_fig = None\n",
        "    regime_drawdown_fig = None\n",
        "else:\n",
        "    combined = pd.concat({BASELINE_LABEL: baseline_regime, CANDIDATE_LABEL: candidate_regime}, axis=1)\n",
        "    regime_comparison = combined\n",
        "    shared_index = sorted(set(baseline_regime.index) | set(candidate_regime.index))\n",
        "    regime_delta = candidate_regime.reindex(shared_index) - baseline_regime.reindex(shared_index)\n",
        "    display(regime_comparison)\n",
        "    display(regime_delta)\n",
        "\n",
        "    sharpe_data = pd.DataFrame({\n",
        "        BASELINE_LABEL: baseline_regime.get(\"sharpe\"),\n",
        "        CANDIDATE_LABEL: candidate_regime.get(\"sharpe\"),\n",
        "    })\n",
        "    regime_sharpe_fig, ax = plt.subplots()\n",
        "    sharpe_data.plot(kind=\"bar\", ax=ax, title=\"Sharpe by regime\")\n",
        "    ax.set_ylabel(\"Sharpe\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    drawdown_data = pd.DataFrame({\n",
        "        BASELINE_LABEL: baseline_regime.get(\"max_drawdown\"),\n",
        "        CANDIDATE_LABEL: candidate_regime.get(\"max_drawdown\"),\n",
        "    })\n",
        "    regime_drawdown_fig, ax = plt.subplots()\n",
        "    drawdown_data.plot(kind=\"bar\", ax=ax, title=\"Max drawdown by regime\")\n",
        "    ax.set_ylabel(\"Drawdown\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "baseline_steps = build_step_frame(baseline_artifacts)\n",
        "candidate_steps = build_step_frame(candidate_artifacts)\n",
        "layer3_rows = []\n",
        "for label, df in [\n",
        "    (BASELINE_LABEL, baseline_steps),\n",
        "    (CANDIDATE_LABEL, candidate_steps),\n",
        "]:\n",
        "    summary = summarize_stability(df) if not df.empty else {\"steps\": 0}\n",
        "    summary[\"label\"] = label\n",
        "    layer3_rows.append(summary)\n",
        "\n",
        "layer3_df = pd.DataFrame(layer3_rows).set_index(\"label\")\n",
        "display(layer3_df)\n",
        "\n",
        "account_value_fig = None\n",
        "turnover_fig = None\n",
        "if not baseline_steps.empty or not candidate_steps.empty:\n",
        "    account_value_fig, ax = plt.subplots()\n",
        "    if \"account_value\" in baseline_steps:\n",
        "        ax.plot(baseline_steps[\"account_value\"], label=BASELINE_LABEL)\n",
        "    if \"account_value\" in candidate_steps:\n",
        "        ax.plot(candidate_steps[\"account_value\"], label=CANDIDATE_LABEL)\n",
        "    ax.set_title(\"Account value trajectory\")\n",
        "    ax.set_ylabel(\"Account value\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    turnover_fig, ax = plt.subplots()\n",
        "    if \"turnover\" in baseline_steps:\n",
        "        ax.plot(baseline_steps[\"turnover\"].reset_index(drop=True), label=BASELINE_LABEL)\n",
        "    if \"turnover\" in candidate_steps:\n",
        "        ax.plot(candidate_steps[\"turnover\"].reset_index(drop=True), label=CANDIDATE_LABEL)\n",
        "    ax.set_title(\"Turnover per step\")\n",
        "    ax.set_ylabel(\"Turnover\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "else:\n",
        "    print(\"No step-level data available for turnover/drawdown diagnostics.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "summary_lines = []\n",
        "if not layer1_delta.empty:\n",
        "    turnover_delta = layer1_delta.get(\"turnover_realized\")\n",
        "    if turnover_delta is not None and not np.isnan(turnover_delta):\n",
        "        summary_lines.append(f\"Execution: turnover delta {turnover_delta:+.2f} (candidate - baseline).\")\n",
        "    fill_delta = layer1_delta.get(\"fill_rate\")\n",
        "    if fill_delta is not None and not np.isnan(fill_delta):\n",
        "        summary_lines.append(f\"Execution: fill-rate delta {fill_delta:+.3f}.\")\n",
        "else:\n",
        "    summary_lines.append(\"Execution layer lacked comparable metrics.\")\n",
        "\n",
        "if not regime_delta.empty:\n",
        "    sharpe_gain = regime_delta.get(\"sharpe\")\n",
        "    if sharpe_gain is not None:\n",
        "        summary_lines.append(\n",
        "            \"Regime: candidate Sharpe beats baseline in \"\n",
        "            + f\"{(sharpe_gain > 0).sum()} / {len(sharpe_gain.dropna())} buckets\"\n",
        "        )\n",
        "else:\n",
        "    summary_lines.append(\"Regime layer missing; cannot assess per-regime gains.\")\n",
        "\n",
        "if not layer3_df.empty:\n",
        "    turnover_candidate = layer3_df.loc[CANDIDATE_LABEL].get(\"avg_turnover\")\n",
        "    turnover_baseline = layer3_df.loc[BASELINE_LABEL].get(\"avg_turnover\")\n",
        "    if turnover_candidate is not None and turnover_baseline is not None:\n",
        "        summary_lines.append(\n",
        "            f\"Stability: avg turnover changed {turnover_candidate - turnover_baseline:+.3f}.\"\n",
        "        )\n",
        "else:\n",
        "    summary_lines.append(\"Stability diagnostics unavailable.\")\n",
        "\n",
        "summary_lines.append(\"Recommendation: run paired seeds or move to qualification once stable.\")\n",
        "\n",
        "display(Markdown(\"\n",
        "\".join(f\"* {line}\" for line in summary_lines)))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "exports = []\n",
        "if not layer1_df.empty:\n",
        "    path = EXPORT_DIR / \"layer1_execution_comparison.csv\"\n",
        "    layer1_df.to_csv(path)\n",
        "    exports.append(path)\n",
        "if not regime_comparison.empty:\n",
        "    path = EXPORT_DIR / \"layer2_regime_slices_comparison.csv\"\n",
        "    regime_comparison.to_csv(path)\n",
        "    exports.append(path)\n",
        "if not regime_delta.empty:\n",
        "    path = EXPORT_DIR / \"layer2_regime_slices_delta.csv\"\n",
        "    regime_delta.to_csv(path)\n",
        "    exports.append(path)\n",
        "if not layer3_df.empty:\n",
        "    path = EXPORT_DIR / \"layer3_stability_summary.csv\"\n",
        "    layer3_df.to_csv(path)\n",
        "    exports.append(path)\n",
        "\n",
        "plot_pairs = [\n",
        "    (regime_sharpe_fig, \"layer2_regime_sharpe.png\"),\n",
        "    (regime_drawdown_fig, \"layer2_regime_drawdown.png\"),\n",
        "    (account_value_fig, \"layer3_account_value.png\"),\n",
        "    (turnover_fig, \"layer3_turnover.png\"),\n",
        "]\n",
        "for fig, filename in plot_pairs:\n",
        "    if fig is not None:\n",
        "        fig.savefig(EXPORT_DIR / filename, bbox_inches=\"tight\")\n",
        "        exports.append(EXPORT_DIR / filename)\n",
        "\n",
        "print(\"Exported artifacts:\")\n",
        "for path in exports:\n",
        "    print(\" -\", path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}