{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# T27 + T28 Ops Validation Notebook\n",
        "\n",
        "Validates paper controller + operations harness behaviors without live broker credentials.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "from research.utils.validation_harness import (\n",
        "    discover_run_artifacts,\n",
        "    hash_json_normalized,\n",
        "    hash_jsonl_normalized,\n",
        "    run_cmd,\n",
        ")\n",
        "\n",
        "PROJECT_ROOT = Path('.').resolve()\n",
        "BASE_DATA_ROOT = PROJECT_ROOT / '.quanto_data'\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "TMP_DATA_ROOT = PROJECT_ROOT / '.quanto_data_notebook_tmp' / f'T27_T28_{timestamp}'\n",
        "TMP_DATA_ROOT.parent.mkdir(parents=True, exist_ok=True)\n",
        "shutil.copytree(BASE_DATA_ROOT, TMP_DATA_ROOT, dirs_exist_ok=True)\n",
        "os.environ['QUANTO_DATA_ROOT'] = str(TMP_DATA_ROOT)\n",
        "\n",
        "PROMOTION_DIR = TMP_DATA_ROOT / 'promotions' / 'candidate'\n",
        "promotions = sorted(PROMOTION_DIR.glob('*.json'))\n",
        "if not promotions:\n",
        "    raise RuntimeError(f'No promotions found under {PROMOTION_DIR}')\n",
        "PROMOTION_PAYLOAD = json.loads(promotions[0].read_text(encoding='utf-8'))\n",
        "CANDIDATE_ID = PROMOTION_PAYLOAD['experiment_id']\n",
        "EXPERIMENTS_ROOT = TMP_DATA_ROOT / 'experiments'\n",
        "all_experiments = sorted(p.name for p in EXPERIMENTS_ROOT.iterdir())\n",
        "UNPROMOTED_ID = next(\n",
        "    exp for exp in all_experiments if not (PROMOTION_DIR / f'{exp}.json').exists() and exp != CANDIDATE_ID\n",
        ")\n",
        "SPEC_PATH = EXPERIMENTS_ROOT / CANDIDATE_ID / 'spec' / 'experiment_spec.json'\n",
        "SPEC_PAYLOAD = json.loads(SPEC_PATH.read_text(encoding='utf-8'))\n",
        "UNIVERSE = SPEC_PAYLOAD.get('symbols') or SPEC_PAYLOAD.get('universe') or []\n",
        "if len(UNIVERSE) < 2:\n",
        "    raise RuntimeError('Candidate spec must list at least two symbols for paper validation.')\n",
        "UNIVERSE = UNIVERSE[:2]\n",
        "CONFIG_ROOT = TMP_DATA_ROOT / 'notebook_configs'\n",
        "CONFIG_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def make_paper_config(experiment_id: str, path: Path) -> Path:\n",
        "    payload = {\n",
        "        'experiment_id': experiment_id,\n",
        "        'execution_mode': 'alpaca_paper',\n",
        "        'universe': UNIVERSE,\n",
        "        'broker': {'alpaca_base_url': 'https://paper-api.alpaca.markets'},\n",
        "        'risk_limits': {'max_gross_exposure': 0.5, 'max_turnover': 0.1, 'max_drawdown': 0.05},\n",
        "        'polling': {'max_poll_seconds': 5, 'poll_interval_seconds': 1},\n",
        "        'reconciliation': {'position_tolerance_shares': 0.5, 'cash_tolerance_usd': 10.0},\n",
        "        'artifacts': {'output_root': str(TMP_DATA_ROOT / 'paper' / experiment_id / 'runs')},\n",
        "    }\n",
        "    path.write_text(json.dumps(payload, indent=2), encoding='utf-8')\n",
        "    return path\n",
        "\n",
        "CANDIDATE_CONFIG = make_paper_config(CANDIDATE_ID, CONFIG_ROOT / 'candidate_paper.json')\n",
        "UNPROMOTED_CONFIG = make_paper_config(UNPROMOTED_ID, CONFIG_ROOT / 'unpromoted_paper.json')\n",
        "print('temp data root:', TMP_DATA_ROOT)\n",
        "print('candidate:', CANDIDATE_ID)\n",
        "print('unpromoted:', UNPROMOTED_ID)\n",
        "print('candidate config:', CANDIDATE_CONFIG)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "from research.ops.alerts import AlertEmitter\n",
        "from research.ops.config import AlertingConfig, BackoffPolicyConfig, OpsConfig, PaperOpsConfig\n",
        "from research.ops.lifecycle import RunLifecycleTracker\n",
        "from research.ops.runtime import BrokerRetryableError, RunExecutor\n",
        "from research.ops.scheduler import MissedRun, ScheduleDecision\n",
        "from research.ops.service import PaperRunOrchestrator\n",
        "from research.paper.config import load_paper_config\n",
        "from research.paper.run import PaperRunner, derive_run_id\n",
        "\n",
        "NOTEBOOK_STATE: Dict[str, Any] = {}\n",
        "\n",
        "class StaticScheduler:\n",
        "    \"\"\"Deterministic scheduler stub for orchestrator-driven tests.\"\"\"\n",
        "\n",
        "    def __init__(self, experiment_id: str, scheduled_for: datetime):\n",
        "        self.experiment_id = experiment_id\n",
        "        self.scheduled_for = scheduled_for\n",
        "        self.history: List[Any] = []\n",
        "        self.run_id: str | None = None\n",
        "\n",
        "    def evaluate(self, *, base_run_id: str, now: datetime | None = None) -> ScheduleDecision:\n",
        "        run_id = f\"{base_run_id}_{self.scheduled_for.strftime('%Y%m%d%H%M')}\"\n",
        "        self.run_id = run_id\n",
        "        return ScheduleDecision(run_id=run_id, scheduled_for=self.scheduled_for, due=True, resume_run_id=None, missed=[])\n",
        "\n",
        "    def mark_active(self, run_id: str, scheduled_for: datetime) -> None:\n",
        "        self.history.append(('active', run_id, scheduled_for.isoformat()))\n",
        "\n",
        "    def mark_terminal(self, run_id: str, state: str) -> None:\n",
        "        self.history.append(('terminal', run_id, state))\n",
        "\n",
        "class NotebookStubRunner(PaperRunner):\n",
        "    \"\"\"Runner stub that writes deterministic artifacts for validation.\"\"\"\n",
        "\n",
        "    def __init__(self, config, *, run_id: str | None = None, scheduled_for: str | None = None):\n",
        "        super().__init__(config, run_id=run_id, scheduled_for=scheduled_for)\n",
        "        logs = self.run_dir / 'logs'\n",
        "        logs.mkdir(parents=True, exist_ok=True)\n",
        "        step_rows = [\n",
        "            {\n",
        "                'idx': 0,\n",
        "                'timestamp': '2024-01-02T13:30:00+00:00',\n",
        "                'mode': 'risk_on',\n",
        "                'weights': {symbol: 1.0 / len(config.universe) for symbol in config.universe},\n",
        "            },\n",
        "            {\n",
        "                'idx': 1,\n",
        "                'timestamp': '2024-01-03T13:30:00+00:00',\n",
        "                'mode': 'defensive',\n",
        "                'weights': {symbol: 0.0 for symbol in config.universe},\n",
        "            },\n",
        "        ]\n",
        "        steps_path = logs / 'steps.jsonl'\n",
        "        steps_path.write_text('\n",
        "'.join(json.dumps(row, sort_keys=True) for row in step_rows), encoding='utf-8')\n",
        "        metrics_payload = {\n",
        "            'summary': {'pnl': 0.0, 'turnover': 0.0, 'reject_rate': 0.0, 'execution_halts': 0},\n",
        "            'execution': {'fills': 0, 'orders_submitted': 0},\n",
        "        }\n",
        "        (self.run_dir / 'metrics.json').write_text(json.dumps(metrics_payload, indent=2, sort_keys=True), encoding='utf-8')\n",
        "        exec_payload = {'latency_ms': 12, 'fees': 0.12}\n",
        "        (self.run_dir / 'execution_metrics.json').write_text(json.dumps(exec_payload, indent=2, sort_keys=True), encoding='utf-8')\n",
        "\n",
        "class ExplodingRunner(PaperRunner):\n",
        "    \"\"\"Runner stub that fails immediately to trigger hard alerts.\"\"\"\n",
        "\n",
        "    def __init__(self, config, *, run_id: str | None = None, scheduled_for: str | None = None):\n",
        "        raise RuntimeError('forced_runner_failure')\n",
        "\n",
        "\n",
        "def clear_alpaca_creds() -> None:\n",
        "    for key in ('ALPACA_API_KEY', 'ALPACA_SECRET_KEY', 'ALPACA_BASE_URL'):\n",
        "        os.environ.pop(key, None)\n",
        "\n",
        "\n",
        "def ensure_dummy_creds() -> None:\n",
        "    os.environ['ALPACA_API_KEY'] = 'demo-key'\n",
        "    os.environ['ALPACA_SECRET_KEY'] = 'demo-secret'\n",
        "    os.environ['ALPACA_BASE_URL'] = 'https://paper-api.alpaca.markets'\n",
        "\n",
        "\n",
        "def build_ops_config(expect_trades: bool = True) -> OpsConfig:\n",
        "    return OpsConfig(\n",
        "        paper_trading=PaperOpsConfig(\n",
        "            cron='* * * * *',\n",
        "            timezone='UTC',\n",
        "            grace_minutes=0,\n",
        "            expect_trades=expect_trades,\n",
        "            runbook_url='ops/runbook.md',\n",
        "            backoff=BackoffPolicyConfig(initial_seconds=0.1, max_seconds=1.0, multiplier=2, max_attempts=1),\n",
        "            alerts=AlertingConfig(hard_channels=['ops/oncall'], soft_channels=['ops/oncall']),\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def collect_alerts() -> list[dict[str, Any]]:\n",
        "    alerts_root = Path(os.environ['QUANTO_DATA_ROOT']) / 'monitoring' / 'alerts'\n",
        "    payloads: list[dict[str, Any]] = []\n",
        "    if not alerts_root.exists():\n",
        "        return payloads\n",
        "    for path in sorted(alerts_root.glob('*.json')):\n",
        "        entries = json.loads(path.read_text(encoding='utf-8'))\n",
        "        payloads.extend(entries)\n",
        "    return payloads\n",
        "\n",
        "print('helper scaffolding ready')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T27: Promotion-only enforcement (unpromoted experiment must fail)\n",
        "clear_alpaca_creds()\n",
        "result = run_cmd([\n",
        "    'python', 'scripts/run_paper.py', '--config', str(UNPROMOTED_CONFIG),\n",
        "], check=False)\n",
        "print('return code:', result.returncode)\n",
        "print(result.stdout)\n",
        "print(result.stderr)\n",
        "assert result.returncode != 0\n",
        "assert 'not promoted' in result.stderr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T27: Paper run rejects missing credentials even for promoted experiments\n",
        "clear_alpaca_creds()\n",
        "result = run_cmd([\n",
        "    'python', 'scripts/run_paper.py', '--config', str(CANDIDATE_CONFIG),\n",
        "], check=False)\n",
        "print('return code:', result.returncode)\n",
        "print(result.stdout)\n",
        "print(result.stderr)\n",
        "assert result.returncode != 0\n",
        "assert 'ALPACA_API_KEY' in result.stderr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T27: Mocked success path using stub runner + orchestrator\n",
        "ensure_dummy_creds()\n",
        "paper_config = load_paper_config(Path(CANDIDATE_CONFIG))\n",
        "ops_config = build_ops_config(expect_trades=True)\n",
        "scheduled_for = datetime(2024, 1, 2, 13, 0, tzinfo=timezone.utc)\n",
        "base_run_id = derive_run_id(paper_config)\n",
        "stub_scheduler = StaticScheduler(paper_config.experiment_id, scheduled_for)\n",
        "orchestrator = PaperRunOrchestrator(\n",
        "    paper_config=paper_config,\n",
        "    ops_config=ops_config,\n",
        "    runner_factory=NotebookStubRunner,\n",
        "    scheduler=stub_scheduler,\n",
        ")\n",
        "report = orchestrator.run(now=scheduled_for)\n",
        "run_dir = Path(report.details['run_dir'])\n",
        "artifacts = discover_run_artifacts(run_dir)\n",
        "print('run id:', report.run_id)\n",
        "print('artifacts:', artifacts)\n",
        "print('summary:', report.summary_json)\n",
        "print('markdown:', report.summary_markdown)\n",
        "NOTEBOOK_STATE['success_run'] = {\n",
        "    'run_id': report.run_id,\n",
        "    'run_dir': run_dir,\n",
        "    'summary_json': Path(report.summary_json),\n",
        "    'scheduled_for': scheduled_for.isoformat(),\n",
        "}\n",
        "print('steps hash:', hash_jsonl_normalized(artifacts['steps']))\n",
        "if 'metrics' in artifacts:\n",
        "    print('metrics hash:', hash_json_normalized(artifacts['metrics']))\n",
        "if 'execution_metrics' in artifacts:\n",
        "    print('execution metrics hash:', hash_json_normalized(artifacts['execution_metrics']))\n",
        "assert run_dir.exists()\n",
        "assert (run_dir / 'metrics.json').exists()\n",
        "assert report.summary_json is not None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T28: Lifecycle + summary validation\n",
        "success_info = NOTEBOOK_STATE['success_run']\n",
        "state_path = Path(os.environ['QUANTO_DATA_ROOT']) / 'paper' / paper_config.experiment_id / 'runs' / success_info['run_id'] / 'state.json'\n",
        "state_payload = json.loads(state_path.read_text(encoding='utf-8'))\n",
        "transition_states = [entry['state'] for entry in state_payload['transitions']]\n",
        "print('transitions:', transition_states)\n",
        "assert transition_states[:3] == ['SCHEDULED', 'STARTING', 'RUNNING']\n",
        "assert transition_states[-1] == 'COMPLETED'\n",
        "summary_payload = json.loads(success_info['summary_json'].read_text(encoding='utf-8'))\n",
        "print('daily summary keys:', sorted(summary_payload))\n",
        "assert summary_payload['run_id'] == success_info['run_id']\n",
        "assert summary_payload['experiment_id'] == paper_config.experiment_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T28: Forced failure -> hard alert\n",
        "failure_scheduler = StaticScheduler(paper_config.experiment_id, scheduled_for + timedelta(minutes=30))\n",
        "orchestrator_failure = PaperRunOrchestrator(\n",
        "    paper_config=paper_config,\n",
        "    ops_config=build_ops_config(expect_trades=False),\n",
        "    runner_factory=ExplodingRunner,\n",
        "    scheduler=failure_scheduler,\n",
        ")\n",
        "try:\n",
        "    orchestrator_failure.run(now=scheduled_for + timedelta(minutes=30))\n",
        "except RuntimeError as exc:\n",
        "    print('expected failure:', exc)\n",
        "NOTEBOOK_STATE['failure_run_id'] = failure_scheduler.run_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T28: Alerts inspection (soft + hard entries must exist)\n",
        "alerts = collect_alerts()\n",
        "print('alerts:', alerts)\n",
        "soft = [entry for entry in alerts if entry['severity'] == 'soft' and entry.get('run_id') == NOTEBOOK_STATE['success_run']['run_id']]\n",
        "hard = [entry for entry in alerts if entry['severity'] == 'hard']\n",
        "assert soft, 'soft alert missing (expect_trades triggered no-trade alert)'\n",
        "assert any(entry.get('run_id') == NOTEBOOK_STATE.get('failure_run_id') for entry in hard)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T28: Missed run detection via real scheduler + orchestrator\n",
        "from research.ops.scheduler import PaperRunScheduler\n",
        "\n",
        "missed_config = PaperOpsConfig(cron='0 0 * * *', timezone='UTC', grace_minutes=5)\n",
        "missed_ops = OpsConfig(paper_trading=missed_config)\n",
        "missed_scheduler = PaperRunScheduler(\n",
        "    paper_config.experiment_id,\n",
        "    missed_config,\n",
        "    data_root=Path(os.environ['QUANTO_DATA_ROOT']) / 'ops_missed'\n",
        ")\n",
        "missed_orchestrator = PaperRunOrchestrator(\n",
        "    paper_config=paper_config,\n",
        "    ops_config=missed_ops,\n",
        "    scheduler=missed_scheduler,\n",
        ")\n",
        "missed_report = missed_orchestrator.run(now=datetime(2024, 1, 2, 15, 0, tzinfo=timezone.utc))\n",
        "print('report status:', missed_report.status)\n",
        "print('missed runs:', missed_report.details.get('missed_runs'))\n",
        "assert missed_report.status == 'IDLE'\n",
        "assert missed_report.details['missed_runs'], 'missed run list should not be empty'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T28: Recovery supervisor / resume safety via RunExecutor\n",
        "from research.ops.scheduler import PaperRunScheduler\n",
        "\n",
        "recovery_tracker = RunLifecycleTracker('exp_recovery', 'recovery_run')\n",
        "recovery_scheduler = PaperRunScheduler(\n",
        "    'exp_recovery',\n",
        "    PaperOpsConfig(cron='* * * * *', timezone='UTC', grace_minutes=0),\n",
        "    data_root=Path(os.environ['QUANTO_DATA_ROOT']) / 'ops_recovery'\n",
        ")\n",
        "recovery_scheduler.mark_active('recovery_run', datetime(2024, 1, 2, 13, 0, tzinfo=timezone.utc))\n",
        "attempts = {'count': 0}\n",
        "\n",
        "\n",
        "def flaky_callable() -> dict[str, Any]:\n",
        "    attempts['count'] += 1\n",
        "    if attempts['count'] < 3:\n",
        "        raise BrokerRetryableError('alpaca_down')\n",
        "    run_dir = Path(os.environ['QUANTO_DATA_ROOT']) / 'paper' / 'exp_recovery' / 'runs' / 'recovery_run'\n",
        "    run_dir.mkdir(parents=True, exist_ok=True)\n",
        "    return {'run_dir': str(run_dir), 'metrics': {'pnl': 0.0}}\n",
        "\n",
        "executor = RunExecutor(\n",
        "    experiment_id='exp_recovery',\n",
        "    run_id='recovery_run',\n",
        "    lifecycle=recovery_tracker,\n",
        "    scheduler=recovery_scheduler,\n",
        "    alert_emitter=AlertEmitter(),\n",
        "    backoff_config=BackoffPolicyConfig(initial_seconds=0.01, max_seconds=0.05, multiplier=2, max_attempts=3),\n",
        ")\n",
        "result = executor.execute(flaky_callable)\n",
        "print('attempts:', attempts['count'])\n",
        "print('final state:', recovery_tracker.current_state)\n",
        "assert attempts['count'] == 3\n",
        "assert recovery_tracker.current_state == 'COMPLETED'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "success_info = NOTEBOOK_STATE['success_run']\n",
        "print('temporary data root:', TMP_DATA_ROOT)\n",
        "print('successful run dir:', success_info['run_dir'])\n",
        "print('summary artifact:', success_info['summary_json'])\n",
        "print('alerts stored under:', Path(os.environ['QUANTO_DATA_ROOT']) / 'monitoring' / 'alerts')\n",
        "print('Notebook validation complete.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}